{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from transformer import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('English_vocab.json', 'r') as f:\n",
    "    eng_vocab = json.load(f)\n",
    "\n",
    "with open('Hindi_vocab.json', 'r') as f:\n",
    "    hn_vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68193, 83630)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eng_vocab), len(hn_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN = '<SOS>'\n",
    "END_TOKEN = '<EOS>'\n",
    "PADDING_TOKEN = '<POS>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eng_vocab[START_TOKEN] = len(eng_vocab)\n",
    "# eng_vocab[END_TOKEN] = len(eng_vocab)+1\n",
    "# eng_vocab[PADDING_TOKEN] = len(eng_vocab)+1\n",
    "\n",
    "\n",
    "# hn_vocab[START_TOKEN] = len(hn_vocab)\n",
    "# hn_vocab[END_TOKEN] = len(hn_vocab)+1\n",
    "# hn_vocab[PADDING_TOKEN] = len(hn_vocab)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_eng = {}\n",
    "index_to_hn = {}\n",
    "\n",
    "for k,v in eng_vocab.items():\n",
    "    index_to_eng[v] = k\n",
    "\n",
    "for k,v in hn_vocab.items():\n",
    "    index_to_hn[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68192, 83629)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_vocab[PADDING_TOKEN], hn_vocab[PADDING_TOKEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('english_sentences.txt', 'r') as f:\n",
    "    english_sentences = f.readlines()\n",
    "\n",
    "with open('hindi_sentences.txt', 'r') as f:\n",
    "    hindi_sentences = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_sentences = [sen.rstrip('\\n') for sen in english_sentences]\n",
    "hindi_sentences = [sen.rstrip('\\n') for sen in hindi_sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,Dataset\n",
    "\n",
    "class TextData(Dataset):\n",
    "    def __init__(self,english_sentences, hindi_sentences) -> None:\n",
    "        super().__init__()\n",
    "        self.english_sentences = english_sentences\n",
    "        self.hindi_sentences = hindi_sentences\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.english_sentences)\n",
    "    \n",
    "    def __getitem__(self, index) :\n",
    "        return self.english_sentences[index],self.hindi_sentences[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TextData(english_sentences, hindi_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset, batch_size)\n",
    "iterator = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('however paes who was partnering australias paul hanley could only go as far as the quarterfinals where they lost to bhupathi and knowles', 'whosoever desires the reward of the world with allah is the reward of the world and of the everlasting life allah is the hearer the seer', 'the value of insects in the biosphere is enormous because they outnumber all other living groups in measure of species richness', 'mithali to anchor indian team against australia in odis', 'after the assent of the honble president on 8thseptember 2016 the 101thconstitutional amendment act 2016 came into existence', 'the court has fixed a hearing for february 12', 'please select the position where the track should be split', 'as per police armys 22rr special operation group sog of police and the central reserve police force crpf cordoned the village and launched search operation in the area', 'jharkhand chief minister hemant soren', 'arvind kumar sho of the sector 5556 police station said a case has been registered under section 376d gang rape of the indian penal code', 'briefing media in new delhi today partys stateincharge anil jain said after the meeting the party will meet the governor to stake claim for government formation in the state', 'jesus responded as he taught in the temple how is it that the scribes say that the christ is the son of david', 'senior leaders of all major parties held electioneering in favour of their candidates', 'meanwhile three people came there on a bike', 'katrina shared the video on instagram', 'he does this because he is angry at the alleged desecration of the indian flag', 'attempts to contact randhawa on his mobile over the past one week have remained futile', 'the alto 800 incorporates a wavefront design a more traditional car look compared to the nano', 'share videos', 'wunderlich and his wife petra are both gardeners who themselves graduated from a normal high school which they attended not reluctantly dirk said', 'the shias venerate him as a member of the family of imams while the sunni simply see him as a person of great sanctity', 'hence we must make sure we ourselves dont become careless not allow anyone else do so', 'mayawati akhilesh yadav seal pact for 2019 polls bspsp not to contest in amethi raebareli', 'they are not seen anywhere', 'joseph dreamed a dream and he told it to his brothers and they hated him all the more', 'they praise night and day without ever tiring', 'some intercity trains like manmadmumbai express gujarat express saurashtra express bandraterminus surat intercity express and mumbai centralahmedabad shatabdi express have been cancelled officials of the central and western railways said', 'both are safe and healthy', 'he sees what they are going through in these critical times and he knows their innermost feelings 2 timothy 3 1 acts 17 27', 'new delhi noted scientist sivan k was appointed chairman of the indian space research organisation on wednesday'), ('आस्ट्रेलिया के पाल हेनली के साथ जोड़ी बनाने वाले पेस मियामी में क्वार्टरफाइनल तक ही पहुंच सके क्योंकि इस दौर में उन्हें भूपति और नोल्स ने हराया था।', 'और जो शख्स अपने आमाल का बदला दुनिया ही में चाहता है तो ख़ुदा के पास दुनिया व आख़िरत दोनों का अज्र मौजूद है और ख़ुदा तो हर शख्स की सुनता और सबको देखता है', 'जैवमंडल में कीड़ों का मूल्य बहुत है क्योंकि प्रजातियों की समृद्धि के मामले में उनकी संख्या अन्य जीव समूहों से ज़्यादा है।', 'आस्ट्रेलिया के खिलाफ वनडे टीम की कमान मिताली को', '8 सितम्बर 2016 को माननीय राष्ट्रपति की स्वीकृति मिलने के बाद 101वां संविधान संशोधन अधिनियम 2016 अस्तित्व में आया', 'अदालत ने इस मामले में आगे की सुनवाई के लिए एक फरवरी की तारीख़ तय की', 'जहाँ पर ट्रैक को विभाजित किया जाना है कृपया वह स्थान चुनें', 'इसके तुरंत बाद सेना की 22 राष्ट्रीय राइफल्स आरआर सीआरपीएफ और पुलिस के स्पेशल ऑपरेशन ग्रुप एसओजी के जवानों द्वारा इलाके की घेराबंदी कर तलाशी अभियान चलाया।', 'झारखंड के मुख्यमंत्री हेमंत सोरेन फोटोः पीटीआई', 'सेक्टर 5556 के एसएचओ अरविंद कुमार ने बताया कि इस मामले में आईपीसी की धारा 376डी गैंगरेप के तहत मामला दर्ज कर लिया गया है।', 'आज नई दिल्ली में मीडिया से बातचीत में पार्टी के राज्य प्रभारी अनिल जैन ने बताया कि बैठक के बाद पार्टी सरकार के गठन का दावा पेश करने के लिए राज्यपाल से मिलेगी।', 'फिर यीशु ने मन्दिर में उपदेश करते हुए यह कहा कि शास्त्री क्योंकर कहते हैं कि मसीह दाऊद का पुत्रा है', 'सभी मुख्य पार्टियों के वरिष्ठ नेताओं ने अपनेअपने उम्मीदवारों के पक्ष में चुनाव प्रचार किया।', 'इसी बीच एक बाइक पर तीन लोग आते दिखाई दिए।', 'कटरीना ने ये वीडियो अपनी इंस्टास्टोरी में शेयर किया है', 'वह ऐसा इसलिए करता है क्योंकि वह भारतीय तिरंगे के कथित अनादर से क्रोधित है', 'रंधावा से एक हफ्ते से उनके मोबाईल पर सम्पर्क करने की कोशिश की गयी लेकिन बात नहीं हो पायी।', 'नैनो की तुलना में अल्टो 800 का डिज़ाइन वेवफ्रंट है जो पारंपरिक कार की तरह दिखता है।', 'वीडियो क्लिप शेयर किए', 'डिर्क और उनकी पत्नी पेट्रा दोनों बागवानी करते हैं और वे दोनों खुद एक सामान्य हाई स्कूल से पढ़े थे', 'शियास उन्हें इमाम के परिवार के सदस्य के रूप में पूजा करते हैं जबकि सुन्नी उन्हें महान पवित्रता के व्यक्ति के रूप में देखते हैं।', 'इसलिए न खुद कोई लापरवाही करनी है और न ही किसी और को लापरवाही करने देना है', '2019 के लिए मायावतीअखिलेश ने जारी की लिस्ट जानिए कौनकहां से लड़ेगा लोकसभा चुनाव', 'दोनों ही कहीं भी दिखाई नहीं पड़ रहे।', 'और यूसुफ ने एक स्वप्न देखा और अपने भाइयों से उसका वर्णन किया  तब वे उस से और भी द्वेष करने लगे।', 'रात और दिन उसकी तस्बीह किया करते हैं और कभी काहिली नहीं करते', 'मध्य रेलवे एवं पश्चिम रेलवे के अधिकारियों के अनुसार मनमाडमुंबई एक्सप्रेस गुजरात एक्सप्रेस सौराष्ट्र एक्सप्रेस बांद्रा टर्मिनस सूरत इंटरसिटी एक्सप्रेस और मुंबई सेंट्रलअहमदाबाद शताब्दी एक्सप्रेस जैसी कुछ इंटरसिटी ट्रेनों को रद्द कर दिया गया है।', 'सभी सुरक्षित और खतरे से बाहर हैं।', 'वह देख सकता है कि इन  संकटों से भरे वक्त  में उन्हें किन  किन मुश्किलों का सामना करना पड़ रहा है और वह उनके दिल की हर बात जानता है ।  2 तीमुथियुस 3 1 प्रेषितों 17 27', 'जानेमाने वैज्ञानिक सिवान के को भारतीय अंतरिक्ष अनुसंधान संगठन इसरो का अध्यक्ष नियुक्त किया गया है।')]\n"
     ]
    }
   ],
   "source": [
    "for batch_num, batch in enumerate(iterator):\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (sentence_embedding): SentenceEmbedding(\n",
       "      (embedding): Embedding(68193, 512)\n",
       "      (postion): PostionEncoding()\n",
       "    )\n",
       "    (enocder_layers): SequentialEncoder(\n",
       "      (0): EncoderLayers(\n",
       "        (selfAttention): MultiheadAttention(\n",
       "          (q_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (k_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm): LayerNormalize()\n",
       "        (feedForward): PositionWiseFeedForward(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (layer2): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (layer3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "          (layer4): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (1): EncoderLayers(\n",
       "        (selfAttention): MultiheadAttention(\n",
       "          (q_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (k_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm): LayerNormalize()\n",
       "        (feedForward): PositionWiseFeedForward(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (layer2): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (layer3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "          (layer4): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (2): EncoderLayers(\n",
       "        (selfAttention): MultiheadAttention(\n",
       "          (q_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (k_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm): LayerNormalize()\n",
       "        (feedForward): PositionWiseFeedForward(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (layer2): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (layer3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "          (layer4): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (3): EncoderLayers(\n",
       "        (selfAttention): MultiheadAttention(\n",
       "          (q_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (k_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm): LayerNormalize()\n",
       "        (feedForward): PositionWiseFeedForward(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (layer2): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (layer3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "          (layer4): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (4): EncoderLayers(\n",
       "        (selfAttention): MultiheadAttention(\n",
       "          (q_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (k_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm): LayerNormalize()\n",
       "        (feedForward): PositionWiseFeedForward(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (layer2): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (layer3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "          (layer4): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (5): EncoderLayers(\n",
       "        (selfAttention): MultiheadAttention(\n",
       "          (q_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (k_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm): LayerNormalize()\n",
       "        (feedForward): PositionWiseFeedForward(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (layer2): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (layer3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "          (layer4): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (sentence_embedding): SentenceEmbedding(\n",
       "      (embedding): Embedding(83630, 512)\n",
       "      (postion): PostionEncoding()\n",
       "    )\n",
       "    (decoder_layers): SequentialDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x DecoderLayers(\n",
       "          (cross_attention): CrossMultiheadAttention(\n",
       "            (q_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (k_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (selfAttention): MultiheadAttention(\n",
       "            (q_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (k_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (norm): LayerNormalize()\n",
       "          (feedForward): PositionWiseFeedForward(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (layer1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (layer2): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "            (layer3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "            (layer4): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=83630, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model = 512\n",
    "max_seq_len = 100 \n",
    "ffn = 2048 \n",
    "drop_prob = 0.1\n",
    "num_head = 8\n",
    "head_dim = 64\n",
    "n_layers = 6\n",
    "\n",
    "transformer = Transformer(d_model, \n",
    "                          max_seq_len, \n",
    "                          ffn, \n",
    "                          drop_prob, \n",
    "                          eng_vocab, \n",
    "                          hn_vocab,\n",
    "                          num_head, \n",
    "                          head_dim, \n",
    "                          n_layers, \n",
    "                          True, \n",
    "                          True,\n",
    "                          True)\n",
    "transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterian = nn.CrossEntropyLoss(ignore_index=hn_vocab[PADDING_TOKEN], reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in transformer.parameters():\n",
    "    if(params.dim() > 1):\n",
    "        nn.init.xavier_uniform_(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(transformer.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEG_INFTY = float('-inf')\n",
    "NEG_INFTY = -1e9\n",
    "\n",
    "def create_masks(eng_batch, hn_batch):\n",
    "    num_sentences = len(eng_batch)\n",
    "    max_sequence_length = 100\n",
    "    look_ahead_mask = torch.full([max_sequence_length, max_sequence_length] , True)\n",
    "    look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1)\n",
    "    encoder_padding_mask = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "    decoder_padding_mask_self_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "    decoder_padding_mask_cross_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "\n",
    "    for idx in range(num_sentences):\n",
    "      eng_sentence_length, hn_sentence_length = len(eng_batch[idx].split()), len(hn_batch[idx].split())\n",
    "      eng_chars_to_padding_mask = np.arange(eng_sentence_length , max_sequence_length)\n",
    "      hn_chars_to_padding_mask = np.arange(hn_sentence_length , max_sequence_length)\n",
    "      encoder_padding_mask[idx, :, eng_chars_to_padding_mask] = True\n",
    "      encoder_padding_mask[idx, eng_chars_to_padding_mask, :] = True\n",
    "      decoder_padding_mask_self_attention[idx, :, hn_chars_to_padding_mask] = True\n",
    "      decoder_padding_mask_self_attention[idx, hn_chars_to_padding_mask, :] = True\n",
    "      decoder_padding_mask_cross_attention[idx, :, eng_chars_to_padding_mask] = True\n",
    "      decoder_padding_mask_cross_attention[idx, hn_chars_to_padding_mask, :] = True\n",
    "\n",
    "    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n",
    "    decoder_self_attention_mask =  torch.where(look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFTY, 0)\n",
    "    decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFTY, 0)\n",
    "    return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Iteration 0 : 0.019243065267801285\n",
      "English: however paes who was partnering australias paul hanley could only go as far as the quarterfinals where they lost to bhupathi and knowles\n",
      "Hindi Translation: आस्ट्रेलिया के पाल हेनली के साथ जोड़ी बनाने वाले पेस मियामी में क्वार्टरफाइनल तक ही पहुंच सके क्योंकि इस दौर में उन्हें भूपति और नोल्स ने हराया था।\n",
      "Hindi Prediction: मॉगों एपीआई मॉगों एपीआई मॉगों मॉगों एपीआई एपीआई मॉगों एपीआई एपीआई एपीआई एपीआई मॉगों मॉगों एपीआई एपीआई मॉगों एपीआई एपीआई एपीआई एपीआई मॉगों एपीआई एपीआई एपीआई एपीआई एपीआई एपीआई एपीआई एपीआई मॉगों ब्रित मॉगों एपीआई एपीआई मॉगों एपीआई मॉगों एपीआई एपीआई मॉगों एपीआई ब्रित मॉगों एपीआई एपीआई एपीआई एपीआई एपीआई मॉगों एपीआई मॉगों एपीआई मॉगों एपीआई ब्रित एबर्ट स्पोक एपीआई एपीआई एपीआई मॉगों मॉगों एपीआई एपीआई आंवावस्था एपीआई एपीआई एपीआई एपीआई एपीआई एपीआई एपीआई एपीआई मॉगों एपीआई ब्रित एपीआई एपीआई ब्रित एपीआई एपीआई मॉगों मॉगों ब्रित एपीआई एपीआई मॉगों ब्रित एपीआई एपीआई ब्रित मॉगों मॉगों एबर्ट एपीआई एपीआई एपीआई एपीआई \n",
      "Evaluation translation (please select the position where the track should be split) : ('अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार अय्यंगार तंत्रिकाविज्ञान तंत्रिकाविज्ञान तंत्रिकाविज्ञान तंत्रिकाविज्ञान तंत्रिकाविज्ञान तंत्रिकाविज्ञान तंत्रिकाविज्ञान तंत्रिकाविज्ञान तंत्रिकाविज्ञान तंत्रिकाविज्ञान तंत्रिकाविज्ञान तंत्रिकाविज्ञान तंत्रिकाविज्ञान तंत्रिकाविज्ञान तंत्रिकाविज्ञान तंत्रिकाविज्ञान तंत्रिकाविज्ञान तंत्रिकाविज्ञान तंत्रिकाविज्ञान तंत्रिकाविज्ञान तंत्रिकाविज्ञान तंत्रिकाविज्ञान तंत्रिकाविज्ञान तंत्रिकाविज्ञान तंत्रिकाविज्ञान तंत्रिकाविज्ञान तंत्रिकाविज्ञान तंत्रिकाविज्ञान तंत्रिकाविज्ञान ',)\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "transformer.train()\n",
    "# transformer.to(device)\n",
    "total_loss = 0\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    iterator = iter(train_loader)\n",
    "    for batch_num, batch in enumerate(iterator):\n",
    "        transformer.train()\n",
    "        eng_batch, hn_batch = batch\n",
    "        encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(eng_batch, hn_batch)\n",
    "        optim.zero_grad()\n",
    "        hn_predictions = transformer(eng_batch,\n",
    "                                     hn_batch,\n",
    "                                     encoder_self_attention_mask,\n",
    "                                     decoder_cross_attention_mask,\n",
    "                                     decoder_self_attention_mask, )\n",
    "        \n",
    "        labels = transformer.decoder.sentence_embedding.batchTokenize(hn_batch, start_token=False, end_token=True)\n",
    "        # print(\"LABELS :- \", labels)\n",
    "        loss = criterian(\n",
    "            hn_predictions.view(-1, len(hn_vocab)),\n",
    "            labels.view(-1)\n",
    "        )\n",
    "        valid_indicies = torch.where(labels.view(-1) == hn_vocab[PADDING_TOKEN], False, True)\n",
    "        loss = loss.sum() / valid_indicies.sum()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        #train_losses.append(loss.item())\n",
    "        if batch_num % 100 == 0:\n",
    "            print(f\"Iteration {batch_num} : {loss.item()}\")\n",
    "            print(f\"English: {eng_batch[0]}\")\n",
    "            print(f\"Hindi Translation: {hn_batch[0]}\")\n",
    "            hn_sentence_predicted = torch.argmax(hn_predictions[0], axis=1)\n",
    "            predicted_sentence = \"\"\n",
    "            for idx in hn_sentence_predicted:\n",
    "              if idx == hn_vocab[END_TOKEN]:\n",
    "                break\n",
    "              predicted_sentence += index_to_hn[idx.item()]+\" \"\n",
    "            print(f\"Hindi Prediction: {predicted_sentence}\")\n",
    "\n",
    "\n",
    "            transformer.eval()\n",
    "            hn_sentence = (\"\",)\n",
    "            eng_sentence = (\"please select the position where the track should be split\",)\n",
    "            for word_counter in range(90):\n",
    "                # print(word_counter)\n",
    "                # if(word_counter == 99):\n",
    "                #    print(eng_sentence, hn_sentence)\n",
    "                #    print(len(hn_sentence[0].split()))\n",
    "                encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask= create_masks(eng_sentence, hn_sentence)\n",
    "                predictions = transformer(eng_sentence,\n",
    "                                          hn_sentence,\n",
    "                                          encoder_self_attention_mask, \n",
    "                                          decoder_cross_attention_mask,\n",
    "                                          decoder_self_attention_mask, )\n",
    "                next_token_prob_distribution = predictions[0][word_counter] # not actual probs\n",
    "                next_token_index = torch.argmax(next_token_prob_distribution).item()\n",
    "                next_token = index_to_hn[next_token_index]\n",
    "                hn_sentence = (hn_sentence[0] + next_token+ ' ', )\n",
    "                # hn_sentence += ' '\n",
    "                if next_token == END_TOKEN:\n",
    "                  print(\"Break Applied\")\n",
    "                  break\n",
    "            \n",
    "            print(f\"Evaluation translation (please select the position where the track should be split) : {hn_sentence}\")\n",
    "            print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68194"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fractal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
